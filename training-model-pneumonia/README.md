Datasets p√∫blico:
Chest X-Ray ‚Äì Pneumonia (Kaggle): ~5.8k radiografias AP de t√≥rax, classes Normal vs Pneumonia; excelente para um primeiro projeto de diagn√≥stico bin√°rio. Exige conta no Kaggle para baixar.

https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia?resource=download

Chest X-Ray Images (Pneumonia)
5,863 images, 2 categories


pip install tensorflow==2.* scikit-learn pandas matplotlib opencv-python


# ü´Å Treinamento de CNN ‚Äî Pneumonia em Raios‚ÄëX de T√≥rax

Este projeto treina uma **rede neural convolucional (CNN)** usando **transfer learning (EfficientNetB0 / Keras‚ÄëTensorFlow)** para classificar imagens de t√≥rax em **Normal** vs **Pneumonia**. O pipeline cobre: prepara√ß√£o/organiza√ß√£o dos dados, cria√ß√£o de `tf.data` datasets, *feature extractor training*, **fine‚Äëtuning**, e avalia√ß√£o final com **relat√≥rio de m√©tricas**, **AUC** e **matriz de confus√£o**. 


---
## üì¶ Dataset (exemplo)
Dataset p√∫blico sugerido para testes/primeiro experimento: **Chest X‚ÄëRay Images (Pneumonia)** (Kaggle) ‚Äî ~5.8k imagens AP; 2 classes. √â necess√°rio ter conta no Kaggle para baixar. 

> Link (Kaggle): *Chest X-Ray Images (Pneumonia)* ‚Äî 5,863 imagens, 2 categorias. 

## Estrutura de Pastas

```
data/
  raw/                 # opcional: imagens por classe; se existir, o script cria o split
    ClasseA/
    ClasseB/
  train/
    ClasseA/
    ClasseB/
  val/
    ClasseA/
    ClasseB/
  test/
    ClasseA/
    ClasseB/
outputs/
  models/
  plots/
  reports/
train_cnn.py
```
- Se `data/train` j√° existir, o script **n√£o** refaz o split. Se s√≥ houver `data/raw`, o script cria `train/`, `val/`, `test/`.

---

## Requisitos

```bash
### 1Ô∏è‚É£ Instalar depend√™ncias
```bash
python3 -m venv .venv
source .venv/bin/activate
python -m pip install --upgrade pip
pip install -r requirements.txt
pip install "tensorflow==2.*" scikit-learn pandas matplotlib opencv-python
```

> üí° **GPU opcional:** se tiver CUDA/cuDNN instalados, o treino acelera bastante. Em CPU tamb√©m funciona (mais lento).

---

## Como Executar

## üöÄ Como executar
1) **Organize os dados**  
   - **Cen√°rio A (r√°pido):** j√° possui `data/train`, `data/val`, `data/test` ‚Üí pule o split.  
   - **Cen√°rio B (split autom√°tico):** coloque as imagens em `data/raw/<Classe>/` e **deixe** `data/train` vazio; o script far√° o split. ÓàÄfileciteÓàÇturn12file2ÓàÅ

2) **Treinar o modelo**
```bash
python train_cnn.py --port 7002
```

Durante o treino, o script executa:
- **Feature extractor** com a base `EfficientNetB0` **congelada** e cabe√ßa densa; *callbacks*: `EarlyStopping`, `ReduceLROnPlateau`, `ModelCheckpoint`.  
- **Fine‚Äëtuning:** descongela a base (mantendo ~200 camadas ainda congeladas), reduz a taxa de aprendizado e treina novamente. 


3) **Sa√≠das principais**
- Modelo final: `outputs/models/model.h5`  
- Melhor checkpoint (feature extractor): `outputs/models/best_feature_extractor.keras`  
- Melhor checkpoint (fine-tuning): `outputs/models/best_finetuned.keras`  
- Relat√≥rio de classifica√ß√£o (precision/recall/F1): `outputs/reports/classification_report.csv`  
- Resumo com AUC e classes: `outputs/reports/summary.json`  
- Matriz de confus√£o: `outputs/plots/confusion_matrix.png`

---

## Vis√£o Geral do Pipeline

## üß† O que o c√≥digo faz (resumo)
- **Seed e diret√≥rios** (`data/`, `outputs/models|plots|reports`).  
- **Split opcional** a partir de `data/raw` (se `data/train` n√£o existir).  
- **Datasets `tf.data`** com `image_dataset_from_directory` (+ *augmentations* no treino, `preprocess_input` da EfficientNet, `cache`/`prefetch`).  
- **Modelo**: EfficientNetB0 `include_top=False`, GAP ‚Üí Dropout(0.25) ‚Üí Dense `softmax`. Otimizador Adam, *loss* `categorical_crossentropy`.  
- **Treino** com *callbacks*; depois **fine‚Äëtuning** com LR menor.  
- **Avalia√ß√£o**: `classification_report`, **AUC** (bin√°ria ou OVR multi‚Äëclasse), **matriz de confus√£o** e **plots**.  
- **Persist√™ncia**: salva checkpoints e `model.h5`. ÓàÄfileciteÓàÇturn12file2ÓàÅ



1. **Seed & Configura√ß√µes**  
   Define *seed* reprodut√≠vel, diret√≥rios (`data`, `outputs`), hiperpar√¢metros (tamanho de imagem, *batch size*, *epochs*, *patience*).

2. **Prepara√ß√£o do Split (opcional)**  
   Se `data/train` n√£o existir, cria `train/`, `val/`, `test/` a partir de `data/raw` usando propor√ß√µes **15% val** e **15% test** por classe. Copia os arquivos mantendo o balan√ßo.

3. **Pipelines `tf.data`**  
   Carrega imagens de `train/`, `val/`, `test/` com `image_dataset_from_directory`. Aplica *augmentations* leves (flip, rota√ß√£o, zoom, transla√ß√£o) **apenas no treino** e `preprocess_input` da EfficientNet. Usa `cache()` + `prefetch()` para desempenho.

4. **Modelo (Transfer Learning)**  
   - **Base:** `EfficientNetB0` com pesos ImageNet, `include_top=False`, *freezada* inicialmente.  
   - **Cabe√ßote:** GAP ‚Üí Dropout(0.25) ‚Üí Dense `softmax` (n√∫mero de classes).  
   - **Compila√ß√£o:** Adam(1e-3), *categorical crossentropy*, *accuracy*.

5. **Treinamento (Feature Extractor)**  
   Treina apenas o cabe√ßote com *callbacks*:  
   - `EarlyStopping` (paciente a **6** √©pocas, monitorando `val_accuracy`)  
   - `ReduceLROnPlateau` (reduz LR ao estagnar `val_loss`)  
   - `ModelCheckpoint` (salva melhor modelo por `val_accuracy`)

6. **Fine-Tuning**  
   Descongela a base (com as **~200 primeiras camadas ainda congeladas** para estabilidade) e recompila com LR menor (1e-5). Treina por mais algumas √©pocas com os mesmos *callbacks*, salvando o melhor `best_finetuned.keras`.

7. **Avalia√ß√£o em Teste**  
   Gera `y_prob`, `y_pred` e calcula:
   - **classification_report** por classe (precision, recall, F1)
   - **AUC** (bin√°ria ou *ovr* multi-classe, quando aplic√°vel)
   - **Matriz de confus√£o** com *plot* salvo em PNG  
   Salva o **modelo final** em `model.h5`.

---

## Detalhamento do C√≥digo (por fun√ß√£o/bloco)

- **Configura√ß√µes e Constantes**: `SEED`, diret√≥rios, `IMG_SIZE=(224,224)`, `BATCH_SIZE=32`, `EPOCHS=30`, `VAL_SPLIT=0.15`, `TEST_SPLIT=0.15`.

- **`ensure_dirs()`**  
  Garante a exist√™ncia de `outputs/models`, `outputs/plots`, `outputs/reports`.

- **`split_from_raw_if_needed()`**  
  - Pula se `data/train` j√° tem conte√∫do.  
  - Se `data/raw` existir, cria `train/val/test` por classe com c√≥pia dos arquivos e *shuffle* controlado pela *seed*.

- **`build_datasets()`**  
  - Cria `train_ds`, `val_ds`, `test_ds` a partir das pastas.  
  - Define *augmentations* (apenas no treino).  
  - Aplica `preprocess_input` da EfficientNet.  
  - Retorna *datasets* com `cache().prefetch()` e `class_names`.

- **`build_model(num_classes)`**  
  - Carrega `EfficientNetB0` (ImageNet), congela a base.  
  - Cabe√ßote: GAP ‚Üí Dropout(0.25) ‚Üí Dense(softmax).  
  - Compila com Adam(1e-3).

- **`unfreeze_and_finetune(model, base, lr=1e-4)`**  
  - Descongela a base para *fine-tuning* (mant√©m as ~200 primeiras camadas congeladas).  
  - Recompila com LR menor (1e-4 no c√≥digo-base; chamada usa 1e-5).

- **`plot_confusion(cm, classes, savepath)`**  
  - Plota e salva a matriz de confus√£o com r√≥tulos e contagens por c√©lula.

- **`main()`**  
  - Cria diret√≥rios, realiza split se necess√°rio.  
  - Constr√≥i *datasets* e obt√©m `class_names`.  
  - Treina (feature extractor) com *callbacks*.  
  - Realiza *fine-tuning*.  
  - Avalia em teste, calcula m√©tricas, salva relat√≥rios, plots e modelo final.

---

## Exemplo de Infer√™ncia (p√≥s-treino)

```python
import tensorflow as tf
import numpy as np
from tensorflow.keras.applications.efficientnet import preprocess_input
from tensorflow.keras.preprocessing import image

model = tf.keras.models.load_model("outputs/models/model.h5")
img_path = "caminho/para/uma_imagem.jpg"

img = image.load_img(img_path, target_size=(224,224))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

prob = model.predict(x)[0]            # vetor de probabilidades
pred_idx = prob.argmax()
print("Classe predita:", pred_idx, "Prob:", prob[pred_idx])
```

> **Observa√ß√£o:** use `class_names` impressas no treinamento para mapear √≠ndices ‚Üí r√≥tulos.

---

## Boas Pr√°ticas (sa√∫de)

- **N√£o substitui avalia√ß√£o cl√≠nica.**  
- Valide com **dados externos** (outras institui√ß√µes).  
- Aten√ß√£o a **vi√©s** (idade, sexo, aparelho, protocolo de aquisi√ß√£o).  
- Cheque **termos de uso** e **privacidade** dos dados. (Consentimento/√©tica).

---

## üßØ Troubleshooting

- **OOM / falta de VRAM**: reduza `BATCH_SIZE`, use `mixed_precision` e/ou imagem menor.  
- **Treino estagnado**: ajuste LR (maior no in√≠cio, menor no *fine-tuning*), revise augmentations.  
- **Desbalanceamento**: use `class_weight` ou t√©cnicas de *resampling*.  
- **AUC NaN**: pode ocorrer em classes √∫nicas no *test*; valide o split e volume de dados.

---

## Licen√ßa & Uso

Este c√≥digo √© fornecido para fins educacionais/experimentais. Verifique a **licen√ßa do dataset** antes de uso acad√™mico/comercial.
