# ðŸ’– Treinamento do Modelo â€“ Preditor de InsuficiÃªncia CardÃ­aca

Este repositÃ³rio contÃ©m o **algoritmo de criaÃ§Ã£o e teste do modelo** utilizado pela API. O pipeline treina um modelo de **classificaÃ§Ã£o binÃ¡ria** (doenÃ§a cardÃ­aca: 0/1) a partir do dataset `heart.csv`, gera mÃ©tricas e persiste **modelo** e **scaler** para uso em produÃ§Ã£o.

---

## ðŸ—‚ï¸ Estrutura

```
.
â”œâ”€â”€ main.py                       # Script de treino/avaliaÃ§Ã£o do modelo
â”œâ”€â”€ heart.csv                     # Dataset de entrada (features + HeartDisease)
â”œâ”€â”€ X_train.csv  X_test.csv       # Features escalonadas (geradas pelo pipeline)
â”œâ”€â”€ y_train.csv  y_test.csv       # Targets correspondentes
â”œâ”€â”€ modelo_insuficiencia_cardiaca.pkl  # Modelo treinado (joblib)
â”œâ”€â”€ scaler_dados.pkl                   # Scaler treinado (joblib)
â””â”€â”€ requirements_model.txt        # DependÃªncias para treino/avaliaÃ§Ã£o
```

---
# Desativar o ambiente virtual, se estiver ativo
```bash
deactivate

# Remover toda a pasta do ambiente virtual
rm -rf .venv


## âš™ï¸ Ambiente

Crie e ative um ambiente virtual e instale as dependÃªncias do arquivo `requirements_model.txt`:

```bash
python3 -m venv .venv
source .venv/bin/activate
python -m pip install --upgrade pip
pip install -r requirements.txt
```

> Se preferir versÃµes mÃ­nimas (nÃ£o fixas), vocÃª pode usar um requirements com **constraints `>=`** (ver seÃ§Ã£o â€œAlternativa com versÃµes mÃ­nimasâ€).

---

## ðŸ§  Pipeline de Treinamento

O script `main.py` executa as seguintes etapas principais:

1. **Carregamento do dataset** `heart.csv` e checagem de nulos.  
2. **CodificaÃ§Ã£o Oneâ€‘Hot** das variÃ¡veis categÃ³ricas com `pd.get_dummies(drop_first=True)`.  
3. **Split treino/teste** estratificado (70/30) com `train_test_split`.  
4. **Escalonamento** das features com `StandardScaler` (fit no treino, transform em treino e teste).  
5. **PersistÃªncia** dos conjuntos escalonados (`X_train.csv`, `X_test.csv`, `y_train.csv`, `y_test.csv`).  
6. **Treinamento** de uma **RegressÃ£o LogÃ­stica** (`solver='liblinear'`, `random_state=42`).  
7. **AvaliaÃ§Ã£o** com acurÃ¡cia e `classification_report` (precision, recall, f1).  
8. **ExportaÃ§Ã£o** dos artefatos: `modelo_insuficiencia_cardiaca.pkl` e `scaler_dados.pkl` (via `joblib`).

> O **alvo** (variÃ¡vel dependente) Ã© a coluna `HeartDisease` (0/1).  
> Para aplicaÃ§Ãµes clÃ­nicas, recomendaâ€‘se acompanhar **Recall/Sensibilidade** (minimizar falsos negativos).

### ExecuÃ§Ã£o

```bash
python main.py --port 7001
```

ApÃ³s a execuÃ§Ã£o, vocÃª deverÃ¡ ver no console as mÃ©tricas do modelo e os arquivos `.pkl`/`.csv` serÃ£o gerados na raiz do projeto.

---

## ðŸ”¬ MÃ©tricas e RelatÃ³rios

O script imprime no console:  
- **AcurÃ¡cia** no conjunto de teste;  
- **Classification Report**: *precision*, *recall*, *f1â€‘score* por classe;  
- *ObservaÃ§Ã£o*: ajuste de limiar pode ser considerado conforme a necessidade (ex.: priorizar recall).

---

## ðŸ” Reprodutibilidade

- `random_state=42` no split e no modelo;  
- `StandardScaler` treinado apenas no treino (evita *data leakage*);  
- As colunas finais usadas pelo modelo ficam registradas na propriedade `model.feature_names_in_` (Ãºtil para alinhar produÃ§Ã£o).

---

## ðŸ§© Handoff para ProduÃ§Ã£o (API)

Na etapa de inferÃªncia (API), Ã© **obrigatÃ³rio alinhar** o vetor de entrada Ã s **mesmas colunas** do treino:

- Usar `model.feature_names_in_` para reordenar/â€œcompletarâ€ dummies;  
- Aplicar **o mesmo `scaler_dados.pkl`** (fit no treino) ao vetor antes de `predict`/`predict_proba`;  
- Em caso de divergÃªncia de colunas, usar `X_train.csv` como **fonte da verdade** para o conjunto de features.

---

## ðŸ§ª Exemplo de uso dos artefatos (inferÃªncia local)

```python
import joblib
import pandas as pd

# 1) Carrega artefatos
model = joblib.load('modelo_insuficiencia_cardiaca.pkl')
scaler = joblib.load('scaler_dados.pkl')

# 2) Novo paciente (exemplo)
novo = pd.DataFrame([{
    "Age": 50, "Sex": "M", "ChestPainType": "NAP", "RestingBP": 125,
    "Cholesterol": 190, "FastingBS": 0, "RestingECG": "Normal",
    "MaxHR": 165, "ExerciseAngina": "N", "Oldpeak": 0.2, "ST_Slope": "Up"
}])

# 3) Oneâ€‘Hot e alinhamento
X_cols = model.feature_names_in_
novo_d = pd.get_dummies(novo, drop_first=True)
for c in set(X_cols) - set(novo_d.columns):
    novo_d[c] = 0
novo_alinhado = novo_d[X_cols]

# 4) Escalonar e prever
X_scaled = scaler.transform(novo_alinhado)
pred = model.predict(X_scaled)[0]
prob = model.predict_proba(X_scaled)[0, 1]
print("Classe:", pred, "Prob.:", f"{prob:.2%}")
```

---

## ðŸªª LicenÃ§a
Uso acadÃªmico e educacional. Ajuste conforme sua necessidade.

---

## ðŸ“¦ Alternativa com versÃµes mÃ­nimas (requirements â€œabertoâ€)

Se preferir dependÃªncias com `>=`:

```
pandas>=2.0.0
scikit-learn>=1.3.0
joblib>=1.3.0
numpy>=1.25.0
# opcionais
matplotlib>=3.8.0
jupyter>=1.0.0
```
